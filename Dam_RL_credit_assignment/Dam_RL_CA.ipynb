{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dam et al. - Credit Assignment during Movement Reinforcement Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import fixed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trajectory \n",
    "\n",
    "Target trajectory: $x = \\alpha y + \\beta sin(\\pi y)$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def plotTrajectory(y, alpha, beta):\n",
    "    '''\n",
    "    Plot invisible trajectory \n",
    "\n",
    "    INPUTS:\n",
    "    y: y values \n",
    "    alpha: alpha parameter value (direction) \n",
    "    beta: beta paramter value (curvature)\n",
    "\n",
    "    OUTPUT:\n",
    "    Figure with invisible trajectory \n",
    "    '''\n",
    "    \n",
    "    x = alpha * y + beta * np.sin(np.pi * y) # divide y by some factor to cut off sine-wave (max y-value works well). May need to also increase bounds of beta term \n",
    "    trajectory = np.array([x, y])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(trajectory[0,:], trajectory[1,:], label='invisible')\n",
    "    plt.title('Trajectory with' + r' $\\alpha$ = ' + f'{alpha:.2f} and' + r' $\\beta$ = ' + f'{beta:.2f}')\n",
    "    plt.xlim([-7, 7])\n",
    "    plt.xlabel('X (cm)')\n",
    "    plt.ylabel('Y (cm)')\n",
    "    plt.ylim([0, 7])\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "_ = widgets.interact(plotTrajectory, y=fixed(np.linspace(0, 7, 500)), alpha=(-1,1,0.1), beta = (-1,1,0.1))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d0bd468d289466fae644bb7ff24e902"
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='alpha', max=1.0, min=-1.0), FloatSlider(value=0.0, d…"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def plotTrajectories(y, alphaT, betaT, alphaG, betaG, condition):\n",
    "    '''\n",
    "    Plot invisible trajectory \n",
    "\n",
    "    INPUTS:\n",
    "    y: y values \n",
    "    alphaT/alphaG: alpha parameter value (direction) [T: true, G: guess]\n",
    "    betaT/betaG: beta paramter value (curvature) [T: true, G: guess]\n",
    "    condition: type of condition, ['alpha', 'beta']\n",
    "\n",
    "    OUTPUT:\n",
    "    Figure with invisible trajectory \n",
    "    '''\n",
    "\n",
    "    # trajectories\n",
    "    traject = lambda alpha, beta, y: alpha * y + beta * np.sin(np.pi * y)\n",
    "    xI = traject(alphaT, betaT, y)\n",
    "    xG = traject(alphaG, betaG, y)\n",
    "\n",
    "    trajectoryI = np.array([xI, y])\n",
    "    trajectoryG = np.array([xG, y])\n",
    "\n",
    "    # reward \n",
    "    if condition == 'alpha':\n",
    "        reward_calc = lambda deltaA, deltaB, W, w: 50 * (1 - (deltaA * W + deltaB * w))\n",
    "    elif condition == 'beta':\n",
    "        reward_calc = lambda deltaA, deltaB, W, w: 50 * (1 - (deltaA * w + deltaB * W))\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    # trajectories \n",
    "    plt.plot(trajectoryI[0,:], trajectoryI[1,:], label='invisible')\n",
    "    plt.plot(trajectoryG[0,:], trajectoryG[1,:], label='trial')\n",
    "    # reward \n",
    "    dA = np.abs(alphaT - alphaG)\n",
    "    dB = np.abs(betaT - betaG)\n",
    "    if dA != 0 and dB != 0:\n",
    "        dA_norm = dA / (dA + dB)\n",
    "        dB_norm = dB / (dA + dB)\n",
    "    else:\n",
    "        dA_norm = dA\n",
    "        dB_norm = dB\n",
    "    reward = reward_calc(dA_norm, dB_norm, 0.8, 0.2)\n",
    "    \n",
    "    plt.text(-5, 0.5, f'{reward:.0f} cents')\n",
    "    plt.title('Invisible:'+ r' $\\alpha$ = ' + f'{alphaT:.1f} and' + r' $\\beta$ = ' + f'{betaT:.1f}' + '\\n' + 'Guess:'+ r' $\\alpha$ = ' + f'{alphaG:.1f} and' + r' $\\beta$ = ' + f'{betaG:.1f}' )\n",
    "    plt.xlim([-7, 7])\n",
    "    plt.xlabel('X (cm)')\n",
    "    plt.ylabel('Y (cm)')\n",
    "    plt.ylim([0, 7])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "_ = widgets.interact(plotTrajectories, y=fixed(np.linspace(0, 7, 500)), alphaT=(-1,1,0.1), betaT=(-1,1,0.1), alphaG=(-1,1.1,0.1), betaG=(-1,1.1,0.1), condition=['alpha', 'beta'])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8314e56f3a8b4e9ab35fc7084e19bad3"
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='alphaT', max=1.0, min=-1.0), FloatSlider(value=0.0, …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b01ba0570bf559b54fac3835c0662045995879e7fc23349796d3c67acbd2c70d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}